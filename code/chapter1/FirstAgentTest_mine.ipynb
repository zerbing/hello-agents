{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938b2e36-f95c-4b0f-8770-335c6bb5bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ .envï¼‰\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# é…ç½®APIå¯†é’¥\n",
    "API_KEY = os.getenv(\"OLLAMA_API_KEY\") or os.getenv(\"API_KEY\") or \"ollama\"\n",
    "BASE_URL = os.getenv(\"OLLAMA_BASE_URL\") or os.getenv(\"BASE_URL\") or \"http://localhost:11434/v1\"\n",
    "MODEL_ID = os.getenv(\"OLLAMA_MODEL\") or os.getenv(\"MODEL_ID\") or \"gpt-oss:latest\"\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "if TAVILY_API_KEY:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = TAVILY_API_KEY\n",
    "\n",
    "# ç³»ç»Ÿæç¤ºè¯\n",
    "AGENT_SYSTEM_PROMPT = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œå¹¶ä½¿ç”¨å¯ç”¨å·¥å…·ä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚\n",
    "\n",
    "# å¯ç”¨å·¥å…·:\n",
    "- `get_weather(city: str)`: æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ã€‚\n",
    "- `get_attraction(city: str, weather: str)`: æ ¹æ®åŸå¸‚å’Œå¤©æ°”æœç´¢æ¨èçš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
    "\n",
    "# è¡ŒåŠ¨æ ¼å¼:\n",
    "ä½ çš„å›ç­”å¿…é¡»ä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ã€‚é¦–å…ˆæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œç„¶åæ˜¯ä½ è¦æ‰§è¡Œçš„å…·ä½“è¡ŒåŠ¨ï¼Œæ¯æ¬¡å›å¤åªè¾“å‡ºä¸€å¯¹Thought-Actionï¼š\n",
    "Thought: [è¿™é‡Œæ˜¯ä½ çš„æ€è€ƒè¿‡ç¨‹å’Œä¸‹ä¸€æ­¥è®¡åˆ’]\n",
    "Action: [è¿™é‡Œæ˜¯ä½ è¦è°ƒç”¨çš„å·¥å…·ï¼Œæ ¼å¼ä¸º function_name(arg_name=\"arg_value\")]\n",
    "\n",
    "# ä»»åŠ¡å®Œæˆ:\n",
    "å½“ä½ æ”¶é›†åˆ°è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿå›ç­”ç”¨æˆ·çš„æœ€ç»ˆé—®é¢˜æ—¶ï¼Œä½ å¿…é¡»åœ¨`Action:`å­—æ®µåä½¿ç”¨ `finish(answer=\"...\")` æ¥è¾“å‡ºæœ€ç»ˆç­”æ¡ˆã€‚\n",
    "\n",
    "è¯·å¼€å§‹å§ï¼\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d9d404-3c95-42f2-8975-436769b3cb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    é€šè¿‡è°ƒç”¨ wttr.in API æŸ¥è¯¢çœŸå®çš„å¤©æ°”ä¿¡æ¯ã€‚\n",
    "    \"\"\"\n",
    "    # APIç«¯ç‚¹ï¼Œæˆ‘ä»¬è¯·æ±‚JSONæ ¼å¼çš„æ•°æ®\n",
    "    url = f\"https://wttr.in/{city}?format=j1\"\n",
    "    \n",
    "    try:\n",
    "        # å‘èµ·ç½‘ç»œè¯·æ±‚\n",
    "        response = requests.get(url)\n",
    "        # æ£€æŸ¥å“åº”çŠ¶æ€ç æ˜¯å¦ä¸º200 (æˆåŠŸ)\n",
    "        response.raise_for_status() \n",
    "        # è§£æè¿”å›çš„JSONæ•°æ®\n",
    "        data = response.json()\n",
    "        \n",
    "        # æå–å½“å‰å¤©æ°”çŠ¶å†µ\n",
    "        current_condition = data['current_condition'][0]\n",
    "        weather_desc = current_condition['weatherDesc'][0]['value']\n",
    "        temp_c = current_condition['temp_C']\n",
    "        \n",
    "        # æ ¼å¼åŒ–æˆè‡ªç„¶è¯­è¨€è¿”å›\n",
    "        return f\"{city}å½“å‰å¤©æ°”ï¼š{weather_desc}ï¼Œæ°”æ¸©{temp_c}æ‘„æ°åº¦\"\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # å¤„ç†ç½‘ç»œé”™è¯¯\n",
    "        return f\"é”™è¯¯ï¼šæŸ¥è¯¢å¤©æ°”æ—¶é‡åˆ°ç½‘ç»œé—®é¢˜ - {e}\"\n",
    "    except (KeyError, IndexError) as e:\n",
    "        # å¤„ç†æ•°æ®è§£æé”™è¯¯\n",
    "        return f\"é”™è¯¯ï¼šè§£æå¤©æ°”æ•°æ®å¤±è´¥ï¼Œå¯èƒ½æ˜¯åŸå¸‚åç§°æ— æ•ˆ - {e}\"\n",
    "\n",
    "def get_attraction(city: str, weather: str) -> str:\n",
    "    \"\"\"\n",
    "    æ ¹æ®åŸå¸‚å’Œå¤©æ°”ï¼Œä½¿ç”¨Tavily Search APIæœç´¢å¹¶è¿”å›ä¼˜åŒ–åçš„æ™¯ç‚¹æ¨èã€‚\n",
    "    \"\"\"\n",
    "    api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        return \"é”™è¯¯ï¼šæœªé…ç½®TAVILY_API_KEYã€‚\"\n",
    "\n",
    "    # åˆå§‹åŒ–Tavilyå®¢æˆ·ç«¯\n",
    "    tavily = TavilyClient(api_key=api_key)\n",
    "    \n",
    "    # æ„é€ ä¸€ä¸ªç²¾ç¡®çš„æŸ¥è¯¢\n",
    "    query = f\"'{city}' åœ¨'{weather}'å¤©æ°”ä¸‹æœ€å€¼å¾—å»çš„æ—…æ¸¸æ™¯ç‚¹æ¨èåŠç†ç”±\"\n",
    "    \n",
    "    try:\n",
    "        # è°ƒç”¨APIï¼Œinclude_answer=Trueä¼šè¿”å›ä¸€ä¸ªç»¼åˆæ€§çš„å›ç­”\n",
    "        response = tavily.search(query=query, search_depth=\"basic\", include_answer=True)\n",
    "        \n",
    "        # Tavilyè¿”å›çš„ç»“æœå·²ç»éå¸¸å¹²å‡€ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨\n",
    "        if response.get(\"answer\"):\n",
    "            return response[\"answer\"]\n",
    "        \n",
    "        # å¦‚æœæ²¡æœ‰ç»¼åˆæ€§å›ç­”ï¼Œåˆ™æ ¼å¼åŒ–åŸå§‹ç»“æœ\n",
    "        formatted_results = []\n",
    "        for result in response.get(\"results\", []):\n",
    "            formatted_results.append(f\"- {result['title']}: {result['content']}\")\n",
    "        \n",
    "        if not formatted_results:\n",
    "             return \"æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ—…æ¸¸æ™¯ç‚¹æ¨èã€‚\"\n",
    "\n",
    "        return \"æ ¹æ®æœç´¢ï¼Œä¸ºæ‚¨æ‰¾åˆ°ä»¥ä¸‹ä¿¡æ¯ï¼š\\n\" + \"\\n\".join(formatted_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"é”™è¯¯ï¼šæ‰§è¡ŒTavilyæœç´¢æ—¶å‡ºç°é—®é¢˜ - {e}\"\n",
    "\n",
    "# å°†æ‰€æœ‰å·¥å…·å‡½æ•°æ”¾å…¥ä¸€ä¸ªå­—å…¸ï¼Œæ–¹ä¾¿åç»­è°ƒç”¨\n",
    "available_tools = {\n",
    "    \"get_weather\": get_weather,\n",
    "    \"get_attraction\": get_attraction,\n",
    "}\n",
    "print(\"âœ… å·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e953fee4-9e3c-4e34-bf48-4ea002c3bb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ™ºèƒ½åŠ©æ‰‹ç±»å®šä¹‰å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "class OpenAICompatibleClient:\n",
    "    \"\"\"\n",
    "    ä¸€ä¸ªç”¨äºè°ƒç”¨ä»»ä½•å…¼å®¹OpenAIæ¥å£çš„LLMæœåŠ¡çš„å®¢æˆ·ç«¯ã€‚\n",
    "    \"\"\"\n",
    "    def __init__(self, model: str, api_key: str, base_url: str):\n",
    "        self.model = model\n",
    "        self.client = OpenAI(api_key=api_key, base_url=base_url)\n",
    "\n",
    "    def generate(self, prompt: str, system_prompt: str) -> str:\n",
    "        \"\"\"è°ƒç”¨LLM APIæ¥ç”Ÿæˆå›åº”ã€‚\"\"\"\n",
    "        print(\"æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\")\n",
    "        try:\n",
    "            messages = [\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ]\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                stream=False\n",
    "            )\n",
    "            message = response.choices[0].message\n",
    "            answer = message.content or \"\"\n",
    "            if not answer and getattr(message, \"tool_calls\", None):\n",
    "                call = message.tool_calls[0]\n",
    "                tool_name = call.function.name\n",
    "                args = {}\n",
    "                if call.function.arguments:\n",
    "                    try:\n",
    "                        args = json.loads(call.function.arguments)\n",
    "                    except json.JSONDecodeError:\n",
    "                        args = {}\n",
    "                args_str = \", \".join(f'{k}=\"{v}\"' for k, v in args.items())\n",
    "                answer = f\"Thought: éœ€è¦è°ƒç”¨å·¥å…·è·å–ä¿¡æ¯\\nAction: {tool_name}({args_str})\"\n",
    "            if not answer:\n",
    "                answer = \"é”™è¯¯ï¼šæ¨¡å‹è¿”å›ç©ºå†…å®¹ã€‚\"\n",
    "            print(\"å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\")\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            print(f\"è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}\")\n",
    "            return \"é”™è¯¯ï¼šè°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚\"\n",
    "\n",
    "class TravelAssistant:\n",
    "    \"\"\"\n",
    "    æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ç±»\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.llm = OpenAICompatibleClient(\n",
    "            model=MODEL_ID,\n",
    "            api_key=API_KEY,\n",
    "            base_url=BASE_URL\n",
    "        )\n",
    "        self.prompt_history = []\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"é‡ç½®å¯¹è¯å†å²\"\"\"\n",
    "        self.prompt_history = []\n",
    "    \n",
    "    def add_user_message(self, message: str):\n",
    "        \"\"\"æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²\"\"\"\n",
    "        self.prompt_history.append(f\"ç”¨æˆ·è¯·æ±‚: {message}\")\n",
    "    \n",
    "    def add_assistant_message(self, message: str):\n",
    "        \"\"\"æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²\"\"\"\n",
    "        self.prompt_history.append(message)\n",
    "    \n",
    "    def add_observation(self, observation: str):\n",
    "        \"\"\"æ·»åŠ è§‚å¯Ÿç»“æœåˆ°å†å²\"\"\"\n",
    "        self.prompt_history.append(f\"Observation: {observation}\")\n",
    "print(\"âœ… æ™ºèƒ½åŠ©æ‰‹ç±»å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab5d3142-c119-46ad-a7a1-ec1aa2e79435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ˜¾ç¤ºå‡½æ•°å®šä¹‰å®Œæˆ!\n"
     ]
    }
   ],
   "source": [
    "def display_conversation(history):\n",
    "    \"\"\"ç¾è§‚åœ°æ˜¾ç¤ºå¯¹è¯å†å²\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“ å¯¹è¯å†å²\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, message in enumerate(history, 1):\n",
    "        if message.startswith(\"ç”¨æˆ·è¯·æ±‚:\"):\n",
    "            print(f\"\\nğŸ‘¤ ç”¨æˆ· [{i}]: {message[5:]}\")\n",
    "        elif message.startswith(\"Thought:\"):\n",
    "            print(f\"\\nğŸ¤” æ€è€ƒ [{i}]: {message[8:].strip()}\")\n",
    "        elif message.startswith(\"Action:\"):\n",
    "            print(f\"ğŸ› ï¸  è¡ŒåŠ¨ [{i}]: {message[7:].strip()}\")\n",
    "        elif message.startswith(\"Observation:\"):\n",
    "            print(f\"ğŸ“Š è§‚å¯Ÿ [{i}]: {message[12:].strip()}\")\n",
    "        else:\n",
    "            print(f\"ğŸ’¬ æ¶ˆæ¯ [{i}]: {message}\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "def parse_action(action_str):\n",
    "    \"\"\"è§£æè¡ŒåŠ¨å­—ç¬¦ä¸²\"\"\"\n",
    "    if action_str.startswith(\"finish\"):\n",
    "        match = re.search(r'finish\\(answer=\"(.*)\"\\)', action_str)\n",
    "        if match:\n",
    "            return \"finish\", {\"answer\": match.group(1)}\n",
    "        return \"finish\", {\"answer\": \"ä»»åŠ¡å®Œæˆ\"}\n",
    "    \n",
    "    tool_name_match = re.search(r\"(\\w+)\\(\", action_str)\n",
    "    if not tool_name_match:\n",
    "        return None, {}\n",
    "    \n",
    "    tool_name = tool_name_match.group(1)\n",
    "    args_match = re.search(r\"\\((.*)\\)\", action_str)\n",
    "    if args_match:\n",
    "        args_str = args_match.group(1)\n",
    "        kwargs = dict(re.findall(r'(\\w+)=\"([^\"]*)\"', args_str))\n",
    "    else:\n",
    "        kwargs = {}\n",
    "    \n",
    "    return tool_name, kwargs\n",
    "print(\"âœ… æ˜¾ç¤ºå‡½æ•°å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc543309-fe16-44a9-9735-bce828b9c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_assistant(user_input, max_iterations=5, display=True):\n",
    "    \"\"\"\n",
    "    è¿è¡Œæ—…è¡ŒåŠ©æ‰‹çš„ä¸»å‡½æ•°\n",
    "    \n",
    "    Args:\n",
    "        user_input: ç”¨æˆ·è¾“å…¥çš„é—®é¢˜\n",
    "        max_iterations: æœ€å¤§å¾ªç¯æ¬¡æ•°\n",
    "        display: æ˜¯å¦æ˜¾ç¤ºå¯¹è¯å†å²\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (æœ€ç»ˆç­”æ¡ˆ, å®Œæ•´çš„å¯¹è¯å†å²)\n",
    "    \"\"\"\n",
    "    assistant = TravelAssistant()\n",
    "    assistant.add_user_message(user_input)\n",
    "    \n",
    "    if display:\n",
    "        print(f\"ğŸ‘¤ ç”¨æˆ·è¾“å…¥: {user_input}\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        if display:\n",
    "            print(f\"\\nğŸ”„ å¾ªç¯ {i+1}/{max_iterations}\")\n",
    "        \n",
    "        # æ„å»ºå®Œæ•´promptå¹¶è°ƒç”¨LLM\n",
    "        full_prompt = \"\\n\".join(assistant.prompt_history)\n",
    "        llm_output = assistant.llm.generate(full_prompt, AGENT_SYSTEM_PROMPT)\n",
    "        # æ¨¡å‹å¯èƒ½ä¼šè¾“å‡ºå¤šä½™çš„Thought-Actionï¼Œéœ€è¦æˆªæ–­\n",
    "        match = re.search(r'(Thought:.*?Action:.*?)(?=\\n\\s*(?:Thought:|Action:|Observation:)|\\Z)', llm_output, re.DOTALL)\n",
    "        if match:\n",
    "            truncated = match.group(1).strip()\n",
    "            if truncated != llm_output.strip():\n",
    "                llm_output = truncated\n",
    "                print(\"âš ï¸ å·²æˆªæ–­å¤šä½™çš„ Thought-Action å¯¹\")\n",
    "        \n",
    "        assistant.add_assistant_message(llm_output)\n",
    "        \n",
    "        if display:\n",
    "            print(f\"ğŸ¤– æ¨¡å‹è¾“å‡º:\\n{llm_output}\")\n",
    "        \n",
    "        # è§£æè¡ŒåŠ¨\n",
    "        action_match = re.search(r\"Action: (.*)\", llm_output, re.DOTALL)\n",
    "        if not action_match:\n",
    "            print(\"âŒ è§£æé”™è¯¯ï¼šæ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚\")\n",
    "            break\n",
    "            \n",
    "        action_str = action_match.group(1).strip()\n",
    "        tool_name, kwargs = parse_action(action_str)\n",
    "        \n",
    "        # å¤„ç†å®Œæˆè¡ŒåŠ¨\n",
    "        if tool_name == \"finish\":\n",
    "            final_answer = kwargs.get(\"answer\", \"ä»»åŠ¡å®Œæˆ\")\n",
    "            if display:\n",
    "                print(f\"ğŸ‰ ä»»åŠ¡å®Œæˆ!\")\n",
    "                print(f\"ğŸ“‹ æœ€ç»ˆç­”æ¡ˆ: {final_answer}\")\n",
    "            return final_answer, assistant.prompt_history\n",
    "        \n",
    "        # å¤„ç†å·¥å…·è°ƒç”¨\n",
    "        if tool_name in available_tools:\n",
    "            if display:\n",
    "                print(f\"ğŸ› ï¸  è°ƒç”¨å·¥å…·: {tool_name}({kwargs})\")\n",
    "            observation = available_tools[tool_name](**kwargs)\n",
    "        else:\n",
    "            observation = f\"é”™è¯¯ï¼šæœªå®šä¹‰çš„å·¥å…· '{tool_name}'\"\n",
    "        \n",
    "        # è®°å½•è§‚å¯Ÿç»“æœ\n",
    "        if display:\n",
    "            print(f\"ğŸ“Š è§‚å¯Ÿç»“æœ: {observation}\")\n",
    "            print(\"=\"*50)\n",
    "        \n",
    "        assistant.add_observation(observation)\n",
    "    \n",
    "    # å¦‚æœè¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°ä»æœªå®Œæˆ\n",
    "    timeout_answer = \"æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ä»æœªå®Œæˆæ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç®€åŒ–æ‚¨çš„é—®é¢˜æˆ–ç¨åé‡è¯•ã€‚\"\n",
    "    if display:\n",
    "        print(f\"â° è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°: {timeout_answer}\")\n",
    "    \n",
    "    return timeout_answer, assistant.prompt_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f6e44eb-ff3d-4060-b4c2-ea3e139bf307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¼€å§‹æµ‹è¯•åŒ—äº¬å¤©æ°”+æ™¯ç‚¹æ¨èç¤ºä¾‹\n",
      "ğŸ‘¤ ç”¨æˆ·è¾“å…¥: ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 1/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: Error code: 404 - {'error': {'message': \"model 'gpt-oss:20b' not found\", 'type': 'api_error', 'param': None, 'code': None}}\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "é”™è¯¯ï¼šè°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚\n",
      "âŒ è§£æé”™è¯¯ï¼šæ¨¡å‹è¾“å‡ºä¸­æœªæ‰¾åˆ° Actionã€‚\n",
      "â° è¾¾åˆ°æœ€å¤§å¾ªç¯æ¬¡æ•°: æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ä»æœªå®Œæˆæ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç®€åŒ–æ‚¨çš„é—®é¢˜æˆ–ç¨åé‡è¯•ã€‚\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š æµ‹è¯•å®Œæˆ!\n",
      "============================================================\n",
      "æœ€ç»ˆç­”æ¡ˆ: æŠ±æ­‰ï¼Œç»è¿‡å¤šæ¬¡å°è¯•ä»æœªå®Œæˆæ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•ç®€åŒ–æ‚¨çš„é—®é¢˜æˆ–ç¨åé‡è¯•ã€‚\n",
      "\n",
      "============================================================\n",
      "ğŸ“ å¯¹è¯å†å²\n",
      "============================================================\n",
      "\n",
      "ğŸ‘¤ ç”¨æˆ· [1]:  ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\n",
      "ğŸ’¬ æ¶ˆæ¯ [2]: é”™è¯¯ï¼šè°ƒç”¨è¯­è¨€æ¨¡å‹æœåŠ¡æ—¶å‡ºé”™ã€‚\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•ç¤ºä¾‹\n",
    "def test_basic_example():\n",
    "    \"\"\"æµ‹è¯•åŒ—äº¬å¤©æ°”+æ™¯ç‚¹æ¨èçš„ç¤ºä¾‹\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹æµ‹è¯•åŒ—äº¬å¤©æ°”+æ™¯ç‚¹æ¨èç¤ºä¾‹\")\n",
    "    user_input = \"ä½ å¥½ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ä¸€ä¸‹ä»Šå¤©åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®å¤©æ°”æ¨èä¸€ä¸ªåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚\"\n",
    "    \n",
    "    final_answer, history = run_assistant(user_input, display=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š æµ‹è¯•å®Œæˆ!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"æœ€ç»ˆç­”æ¡ˆ: {final_answer}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²\n",
    "    display_conversation(history)\n",
    "    \n",
    "    return final_answer, history\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•ç¤ºä¾‹\n",
    "final_answer, history = test_basic_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c735c1-eb3e-40e7-8b70-2be941798187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_travel_assistant():\n",
    "    \"\"\"\n",
    "    äº¤äº’å¼æ—…è¡ŒåŠ©æ‰‹\n",
    "    \"\"\"\n",
    "    print(\"ğŸŒ æ¬¢è¿ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹!\")\n",
    "    print(\"ğŸ’¡ æ‚¨å¯ä»¥è¯¢é—®ä»»ä½•åŸå¸‚çš„å¤©æ°”å’Œæ—…æ¸¸æ™¯ç‚¹æ¨è\")\n",
    "    print(\"âŒ è¾“å…¥ 'quit' æˆ– 'é€€å‡º' æ¥ç»“æŸå¯¹è¯\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"ğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜: \").strip()\n",
    "        \n",
    "        if user_input.lower() in ['quit', 'é€€å‡º', 'exit']:\n",
    "            print(\"ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨æ™ºèƒ½æ—…è¡ŒåŠ©æ‰‹ï¼Œå†è§!\")\n",
    "            break\n",
    "        \n",
    "        if not user_input:\n",
    "            print(\"âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜\")\n",
    "            continue\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ğŸ”„ æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...\")\n",
    "        \n",
    "        final_answer, history = run_assistant(user_input, display=True)\n",
    "        \n",
    "        print(\"\\nğŸ¯ æœ€ç»ˆå›ç­”:\")\n",
    "        print(\"=\"*30)\n",
    "        print(final_answer)\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        # è¯¢é—®æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²\n",
    "        show_history = input(\"\\nğŸ“– æ˜¯å¦æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²? (y/n): \").strip().lower()\n",
    "        if show_history in ['y', 'yes', 'æ˜¯']:\n",
    "            display_conversation(history)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ”„ å‡†å¤‡æ¥å—ä¸‹ä¸€ä¸ªé—®é¢˜...\\n\")\n",
    "\n",
    "# å¿«é€Ÿæµ‹è¯•å‡½æ•°\n",
    "def quick_test(city=\"ä¸Šæµ·\"):\n",
    "    \"\"\"å¿«é€Ÿæµ‹è¯•æŒ‡å®šåŸå¸‚çš„å¤©æ°”å’Œæ™¯ç‚¹\"\"\"\n",
    "    user_input = f\"è¯·å¸®æˆ‘æŸ¥è¯¢{city}çš„å¤©æ°”ï¼Œå¹¶æ¨èé€‚åˆçš„æ—…æ¸¸æ™¯ç‚¹\"\n",
    "    print(f\"ğŸš€ å¿«é€Ÿæµ‹è¯•: {user_input}\")\n",
    "    final_answer, _ = run_assistant(user_input, display=True)\n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc58c911-8502-4cf5-aa3f-a9f57a94b679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é€‰æ‹©è¿è¡Œæ¨¡å¼:\n",
      "1. è¿è¡Œæµ‹è¯•ç¤ºä¾‹ (åŒ—äº¬)\n",
      "2. äº¤äº’æ¨¡å¼\n",
      "3. å¿«é€Ÿæµ‹è¯•å…¶ä»–åŸå¸‚\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯·è¾“å…¥é€‰æ‹© (1/2/3):  3\n",
      "è¯·è¾“å…¥è¦æµ‹è¯•çš„åŸå¸‚:  ä¼¦æ•¦\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ å¿«é€Ÿæµ‹è¯•: è¯·å¸®æˆ‘æŸ¥è¯¢ä¼¦æ•¦çš„å¤©æ°”ï¼Œå¹¶æ¨èé€‚åˆçš„æ—…æ¸¸æ™¯ç‚¹\n",
      "ğŸ‘¤ ç”¨æˆ·è¾“å…¥: è¯·å¸®æˆ‘æŸ¥è¯¢ä¼¦æ•¦çš„å¤©æ°”ï¼Œå¹¶æ¨èé€‚åˆçš„æ—…æ¸¸æ™¯ç‚¹\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 1/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "Thought: æˆ‘éœ€è¦å…ˆæŸ¥è¯¢ä¼¦æ•¦çš„å®æ—¶å¤©æ°”ï¼Œè¿™æ ·æ‰èƒ½æ ¹æ®å¤©æ°”æƒ…å†µæ¨èåˆé€‚çš„æ—…æ¸¸æ™¯ç‚¹ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†è°ƒç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·è·å–ä¼¦æ•¦çš„å¤©æ°”ä¿¡æ¯ã€‚ \n",
      "Action: get_weather(city=\"ä¼¦æ•¦\")\n",
      "ğŸ› ï¸  è°ƒç”¨å·¥å…·: get_weather({'city': 'ä¼¦æ•¦'})\n",
      "ğŸ“Š è§‚å¯Ÿç»“æœ: ä¼¦æ•¦å½“å‰å¤©æ°”ï¼šPartly cloudyï¼Œæ°”æ¸©16æ‘„æ°åº¦\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 2/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "Thought: ç°åœ¨æˆ‘å·²ç»æŸ¥è¯¢åˆ°äº†ä¼¦æ•¦çš„å®æ—¶å¤©æ°”æƒ…å†µï¼šéƒ¨åˆ†å¤šäº‘ï¼Œæ°”æ¸©ä¸º16æ‘„æ°åº¦ã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘å°†æ ¹æ®è¿™ä¸ªå¤©æ°”æƒ…å†µæ¨èé€‚åˆåœ¨ä¼¦æ•¦æ¸¸ç©çš„æ—…æ¸¸æ™¯ç‚¹ã€‚ \n",
      "Action: get_attraction(city=\"ä¼¦æ•¦\", weather=\"Partly cloudy\")\n",
      "ğŸ› ï¸  è°ƒç”¨å·¥å…·: get_attraction({'city': 'ä¼¦æ•¦', 'weather': 'Partly cloudy'})\n",
      "ğŸ“Š è§‚å¯Ÿç»“æœ: åœ¨ä¼¦æ•¦å¤šäº‘å¤©æ°”ä¸‹ï¼Œä¼¦æ•¦çœ¼æ˜¯æœ€å€¼å¾—å»çš„æ™¯ç‚¹ã€‚å®ƒæä¾›äº†ä¼Ÿå¤§çš„åŸå¸‚æ™¯è§‚ã€‚æ­¤å¤–ï¼Œåšç‰©é¦†å’Œç”»å»Šä¹Ÿé€‚åˆå‚è§‚ã€‚\n",
      "==================================================\n",
      "\n",
      "ğŸ”„ å¾ªç¯ 3/5\n",
      "æ­£åœ¨è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹...\n",
      "å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸã€‚\n",
      "ğŸ¤– æ¨¡å‹è¾“å‡º:\n",
      "Thought: æˆ‘å·²ç»è·å–äº†ä¼¦æ•¦çš„å¤©æ°”æƒ…å†µå’Œé€‚åˆçš„æ—…æ¸¸æ™¯ç‚¹æ¨èã€‚å½“å‰å¤©æ°”ä¸ºéƒ¨åˆ†å¤šäº‘ï¼Œæ¨èæ—…æ¸¸æ™¯ç‚¹ä¸ºä¼¦æ•¦çœ¼ï¼ŒåŒæ—¶åšç‰©é¦†å’Œç”»å»Šä¹Ÿéå¸¸é€‚åˆåœ¨è¿™ç§å¤©æ°”ä¸‹å‚è§‚ã€‚æœ€ç»ˆæˆ‘å°†æ•´åˆè¿™äº›ä¿¡æ¯å¹¶ç»™å‡ºç”¨æˆ·çš„å»ºè®®ã€‚ \n",
      "Action: finish(answer=\"ä¼¦æ•¦å½“å‰å¤©æ°”ä¸ºéƒ¨åˆ†å¤šäº‘ï¼Œæ°”æ¸©16æ‘„æ°åº¦ã€‚æ ¹æ®å¤©æ°”æƒ…å†µï¼Œæ¨èæ‚¨å»ä¼¦æ•¦çœ¼æ¬£èµåŸå¸‚æ™¯è§‚ï¼Œæ­¤å¤–åšç‰©é¦†å’Œç”»å»Šä¹Ÿæ˜¯å¾ˆå¥½çš„é€‰æ‹©ã€‚\")\n",
      "ğŸ‰ ä»»åŠ¡å®Œæˆ!\n",
      "ğŸ“‹ æœ€ç»ˆç­”æ¡ˆ: ä¼¦æ•¦å½“å‰å¤©æ°”ä¸ºéƒ¨åˆ†å¤šäº‘ï¼Œæ°”æ¸©16æ‘„æ°åº¦ã€‚æ ¹æ®å¤©æ°”æƒ…å†µï¼Œæ¨èæ‚¨å»ä¼¦æ•¦çœ¼æ¬£èµåŸå¸‚æ™¯è§‚ï¼Œæ­¤å¤–åšç‰©é¦†å’Œç”»å»Šä¹Ÿæ˜¯å¾ˆå¥½çš„é€‰æ‹©ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ä¸»å¯åŠ¨å…¥å£\n",
    "if __name__ == \"__main__\":\n",
    "    # å¯ä»¥é€‰æ‹©ç›´æ¥è¿è¡Œæµ‹è¯•ç¤ºä¾‹\n",
    "    print(\"é€‰æ‹©è¿è¡Œæ¨¡å¼:\")\n",
    "    print(\"1. è¿è¡Œæµ‹è¯•ç¤ºä¾‹ (åŒ—äº¬)\")\n",
    "    print(\"2. äº¤äº’æ¨¡å¼\")\n",
    "    print(\"3. å¿«é€Ÿæµ‹è¯•å…¶ä»–åŸå¸‚\")\n",
    "    \n",
    "    choice = input(\"è¯·è¾“å…¥é€‰æ‹© (1/2/3): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        test_basic_example()\n",
    "    elif choice == \"2\":\n",
    "        interactive_travel_assistant()\n",
    "    elif choice == \"3\":\n",
    "        city = input(\"è¯·è¾“å…¥è¦æµ‹è¯•çš„åŸå¸‚: \").strip() or \"ä¸Šæµ·\"\n",
    "        quick_test(city)\n",
    "    else:\n",
    "        print(\"æ— æ•ˆé€‰æ‹©ï¼Œè¿è¡Œæµ‹è¯•ç¤ºä¾‹...\")\n",
    "        test_basic_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ad2cf-d240-4322-9e91-5da2af51f53f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
